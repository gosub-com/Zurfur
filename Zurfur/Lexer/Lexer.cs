using System;
using System.Collections.Generic;
using System.IO;
using System.Reflection.Emit;

namespace Gosub.Zurfur.Lex
{
    /// <summary>
    /// Lexical analyzer - scan and separate tokens in a file.
    /// Provide services for the editor to modify the text and re-tokenize
    /// whenever it changes.  Tokens never cross line boundaries.
    /// Default's to ScanText scanner.
    /// </summary>
    sealed public class Lexer
    {
        // Strings and tokens buffer
        List<string> mLines = new List<string>();
        List<Token[]> mTokens = new List<Token[]>();
        Token[] mMetaTokens;
        public bool ShowMetaTokens;

        Scanner mScanner = ScanText.Empty;

        // Be kind to the GC
        MinTern mMinTern = new MinTern();
        List<Token> mTokenBuffer = new List<Token>();


        /// <summary>
        /// This token returned at end of file, always ""
        /// </summary>
        public Token EndToken { get; private set; } = new Token("", 0, 2);

        /// <summary>
        /// Optional location of cursor (y = -1 if not set)
        /// </summary>
        public TokenLoc Cursor = new TokenLoc(0, -1);

        public Lexer()
        {
            // Must have at least one line of text
            mLines.Add("");
            mTokens.Add(new Token[0]);
            mMetaTokens = new Token[1] { EndToken };
        }

        public Lexer(Scanner scanner) : this()
        {
            mScanner = scanner;
        }

        /// <summary>
        /// NOTE: Lexer dafaults to object comparison, so don't change that
        /// behavior now.  Use this function to compare text files.
        /// </summary>
        public bool Equals(Lexer lex)
        {
            if (lex == this)
                return true;
            if (LineCount != lex.LineCount)
                return false;
            for (int i = 0; i < LineCount; i++)
                if (mLines[i] != lex.mLines[i])
                    return false;
            return true;
        }

        public override string ToString()
        {
            return mLines.Count.ToString() + " Lines";
        }

        /// <summary>
        /// Defaults to ScanText.  Re-scans all text when set (unless it's the same object)
        /// </summary>
        public Scanner Scanner
        {
            set 
            {
                if (mScanner == value)
                    return;
                mScanner = value;
                Scan(mLines.ToArray());
            }
            get
            {
                return mScanner;
            }
        }

        /// <summary>
        /// Clone the lexer and all tokens.  All markup information is discarded.
        /// </summary>
        public Lexer Clone()
        {
            var lex = new Lexer();
            lex.ShowMetaTokens = ShowMetaTokens;
            lex.mLines = new List<string>(mLines);
            lex.mTokens.Clear();
            foreach (var tokenLine in mTokens)
            {
                var newTokens = new Token[tokenLine.Length];
                for (int i = 0;  i < newTokens.Length;  i++)
                    newTokens[i] = tokenLine[i].Clone();
                lex.mTokens.Add(newTokens);
            }
            lex.EndToken.Y = lex.mTokens.Count;
            lex.mMetaTokens = new Token[mMetaTokens.Length];
            for (int i = 0; i < mMetaTokens.Length; i++)
                lex.MetaTokens[i] = mMetaTokens[i].Clone();
            lex.mScanner = mScanner;
            lex.Cursor = Cursor;
            return lex;
        }

        /// <summary>
        /// Meta tokens, a fancy word for "extra" tokens used to markup the text.
        /// Includes invisible tokens with errors (like the ';') and other stuff
        /// that could be generated by the parser.  These are cloned and sorted
        /// when set, but the return value is the internal data structure which
        /// should not be modified.
        /// NOTE: EndToken is always included in this set.
        /// </summary>
        public Token[]MetaTokens
        {
            get => mMetaTokens;
            set
            {
                List<Token> tokens = new List<Token>(value.Length + 1);
                foreach (var token in value)
                    if (token != EndToken)
                        tokens.Add(token);
                tokens.Add(EndToken);
                mMetaTokens = tokens.ToArray();
                Array.Sort(mMetaTokens, (a, b) => a.Location < b.Location ? -1 : (a.Location == b.Location ? 0 : 1) );
            }
        }

        /// <summary>
        /// Returns the number of lines of text
        /// </summary>
        public int LineCount { get { return mLines.Count; } }

        /// <summary>
        /// Returns a line of text
        /// </summary>
        public string GetLine(int index) { return mLines[index]; }

        public Token []GetLineTokens(int line) { return mTokens[line]; }

        /// <summary>
        /// Returns v, bounded by min and max (or min if min >= max)
        /// </summary>
        int Bound(int v, int min, int max)
        {
            return Math.Max(Math.Min(v, max), min);
        }

        /// <summary>
        /// Gets a section of text.
        /// </summary>
        public string[] GetText(TokenLoc start, TokenLoc end)
        {
            // Bounds check parameters
            start.Y = Bound(start.Y, 0, mLines.Count-1);
            start.X = Bound(start.X, 0, mLines[start.Y].Length);
            end.Y = Bound(end.Y, 0, mLines.Count-1);
            end.X = Bound(end.X, 0, mLines[end.Y].Length);
            if (end.Y < start.Y)
                end.Y = start.Y;
            if (start.Y == end.Y && end.X < start.X)
                end.X = start.X;

            int startIndex = start.X;
            int endIndex = end.X;

            if (start.Y == end.Y && startIndex >= endIndex)
                return new string[0];

            if (start.Y == end.Y)
            {
                return new string[] { mLines[start.Y].Substring(startIndex, endIndex-startIndex) };
            }

            // Break up the first and last line at the start position
            string []lines = new string[end.Y-start.Y+1];
            lines[0] = mLines[start.Y].Substring(startIndex);
            for (int i = 1; i < lines.Length-1; i++)
                lines[i] = mLines[start.Y+i];
            lines[end.Y-start.Y] = mLines[end.Y].Substring(0, endIndex);
            return lines;
        }

        /// <summary>
        /// Returns a copy of all the text
        /// </summary>
        public string[] GetText()
        {
            return mLines.ToArray();
        }

        /// <summary>
        /// Replace a section of text.  This function is used to insert, 
        /// delete, and change a section of text.  It will re-analyze the
        /// text (replacing all tokens on all lines that were changed)
        /// and updating the positions of the tokens.
        /// RETURNS: The new end location of the inserted text
        /// </summary>
        public TokenLoc ReplaceText(string[] replacementText,
                         TokenLoc start, TokenLoc end)
        {
            // Bounds check parameters
            start.Y = Bound(start.Y, 0, mLines.Count-1);
            start.X = Bound(start.X, 0, mLines[start.Y].Length);
            end.Y = Bound(end.Y, 0, mLines.Count-1);
            end.X = Bound(end.X, 0, mLines[end.Y].Length);
            if (end.Y < start.Y)
                end.Y = start.Y;
            if (start.Y == end.Y && end.X < start.X)
                end.X = start.X;

            int startIndex = start.X;
            int endIndex = end.X;

            // Adjust first line
            if (start.Y != end.Y || startIndex != endIndex)
                mLines[start.Y] = mLines[start.Y].Substring(0, startIndex)
                                    + mLines[end.Y].Substring(endIndex);

            // Remove unused lines
            if (start.Y != end.Y)
            {
                mLines.RemoveRange(start.Y+1, end.Y-start.Y);
                mTokens.RemoveRange(start.Y+1, end.Y-start.Y);
            }

            // Start and end are the same
            end.Y = start.Y;
            endIndex = startIndex;

            // Insert new text
            if (replacementText != null && replacementText.Length != 0)
            {
                // Break up the first line at the start position
                string startStr = mLines[start.Y].Substring(0, startIndex);
                string endStr = mLines[start.Y].Substring(startIndex);

                if (replacementText.Length <= 1)
                {
                    mLines[start.Y] = startStr + replacementText[0] + endStr;
                    endIndex = startStr.Length + replacementText[0].Length;
                }
                else
                {
                    // Insert new lines
                    mLines[start.Y] = startStr + replacementText[0];
                    for (int i = 1; i < replacementText.Length; i++)
                    {
                        mLines.Insert(start.Y+i, replacementText[i]);
                        mTokens.Insert(start.Y+i, Array.Empty<Token>());
                    }
                    end.Y = start.Y + replacementText.Length-1;
                    endIndex = replacementText[replacementText.Length-1].Length;
                    mLines[end.Y] += endStr;
                }
            }

            // Re-scan the updated text lines
            for (int i = start.Y; i <= end.Y; i++)
                mTokens[i] = ScanLine(mLines[i], i);

            // Re-adjust token line positions
            for (int i = start.Y; i < mTokens.Count; i++)
                foreach (Token token in mTokens[i])
                    token.Y = i;

            // Calculate end of inserted text
            EndToken.Location = new TokenLoc(0, mLines.Count);
            end.X = endIndex;
            return end;
        }

        /// <summary>
        /// Delete all data, then scan tokens from strings using the current `Scanner`.
        /// </summary>
        public void Scan(string[] lines)
        {
            mTokens.Clear();

            // Must have at least one line of text
            if (lines.Length == 0)
                lines = new string[1] { "" };
            mLines = new List<string>(lines.Length);

            // For each line
            for (int lineIndex = 0; lineIndex < lines.Length; lineIndex++)
            {
                mLines.Add(lines[lineIndex]);
                mTokens.Add(ScanLine(lines[lineIndex], lineIndex));
            }
            EndToken.Location = new TokenLoc(0, mLines.Count+1);
        }

        /// <summary>
        /// Delete all data, then scan tokens from a stream using the current `Scanner`.
        /// </summary>
        public void Scan(Stream s)
        {
            mTokens.Clear();
            mLines.Clear();
            var tr = new StreamReader(s);
            while (!tr.EndOfStream)
            {
                var line = tr.ReadLine();
                mLines.Add(line);
                mTokens.Add(ScanLine(line, mTokens.Count));
            }
            if (mLines.Count == 0)
            {
                // Must have at least one line of text
                mLines.Add("");
                mTokens.Add(new Token[0]);
            }
            EndToken.Location = new TokenLoc(0, mLines.Count + 1);
        }

        Token [] ScanLine(string line, int lineIndex)
        {
            mTokenBuffer.Clear();
            Scanner.ScanLine(line, mTokenBuffer, mMinTern);

            var tokens = mTokenBuffer.ToArray();
            mTokenBuffer.Clear();

            // Set line index
            foreach (var token in tokens)
                token.Y = lineIndex;

            // Set begin/end index
            if (tokens.Length != 0)
            {
                tokens[0].SetBolnByLexerOnly();
                tokens[tokens.Length - 1].SetEolnByLexerOnly();
            }

            return tokens;
        }

        /// <summary>
        /// Iterator to return all tokens
        /// </summary>
        public Enumerator GetEnumerator()
        {
            return new Enumerator(this);
        }

        /// <summary>
        /// Iterate through all tokens, starting at startLine
        /// </summary>
        public Enumerator GetEnumeratorStartAtLine(int startLine)
        {
            return new Enumerator(this, startLine);
        }

        /// <summary>
        /// Enumerate tokens in the lexer.  Call MoveNextLine to skip to next line
        /// </summary>
        public struct Enumerator:IEnumerator<Token>
        {
            Lexer		mLexer;
            int			mIndexLine;
            int			mIndexToken;
            Token		mCurrent;
            Token       []mCurrentLine;
            static Token sEmptyToken = new Token();

            public IEnumerator<Token> GetEnumerator() { return this; }
            public void Dispose() { }
            public Token Current { get { return mCurrent; } }
            public int CurrentLineTokenCount { get { return mCurrentLine.Length; } }
            object System.Collections.IEnumerator.Current { get { return mCurrent; } }

            /// <summary>
            /// Enumerate all tokens
            /// </summary>
            public Enumerator(Lexer lexer)
            {
                mLexer = lexer;
                mIndexLine = 0;
                mIndexToken = 0;
                mCurrentLine = mLexer.mTokens.Count <= 0 ? Array.Empty<Token>() : mLexer.mTokens[0];
                mCurrent = null;
            }

            /// <summary>
            /// Enumerate all tokens, starting at startLine
            /// </summary>
            public Enumerator(Lexer lexer, int startLine)
            {
                mLexer = lexer;
                mIndexLine = Math.Max(0, startLine);
                mIndexToken = 0;
                mCurrentLine = mLexer.mTokens.Count <= mIndexLine ? Array.Empty<Token>() : mLexer.mTokens[mIndexLine];
                mCurrent = null;
            }

            /// <summary>
            /// Returns the next token on the line, or "" if at end of line
            /// </summary>
            public Token PeekOnLine(int i = 0)
            {
                if (mIndexToken+i < mCurrentLine.Length)
                    return mCurrentLine[mIndexToken+i];
                return Token.Empty;
            }

            public void Reset()
            {
                throw new NotSupportedException("Reset on lexer enumerator is not supported");
            }

            /// <summary>
            /// Move to next token, skipping blank lines, returns EndToken at end of file
            /// </summary>
            public bool MoveNext()
            {
                // More tokens on this line?
                if (mIndexToken < mCurrentLine.Length)
                {
                    mCurrent = mCurrentLine[mIndexToken++];
                    return true;
                }
                // Move to next non-empty line
                mIndexToken = 0;
                do
                {
                    mIndexLine++;
                } while (mIndexLine < mLexer.mTokens.Count && mLexer.mTokens[mIndexLine].Length == 0);
                
                // Return next token
                if (mIndexLine < mLexer.mTokens.Count)
                {
                    mCurrentLine = mLexer.mTokens[mIndexLine];
                    mCurrent = mCurrentLine[mIndexToken++];
                    return true;
                }
                if (mCurrent != mLexer.EndToken)
                {
                    mCurrent = mLexer.EndToken;
                    mIndexToken = mCurrentLine.Length + 1;
                    return true;
                }
                mCurrent = null;
                return false;
            }

            /// <summary>
            /// Move to next line, blank lines return empty token
            /// </summary>
            public bool MoveNextLine()
            {
                mIndexToken = 0;
                if (mIndexLine < mLexer.mTokens.Count)
                {
                    mCurrentLine = mLexer.mTokens[mIndexLine++];
                    mCurrent = mCurrentLine.Length == 0 ? sEmptyToken : mCurrentLine[mIndexToken++];
                    return true;
                }
                mCurrent = null;
                return false;
            }

        }
    }
}
